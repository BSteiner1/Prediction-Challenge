---
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) 
library(gapminder) 
library(broom)
library(ggplot2)
library(reshape2)
knitr::opts_chunk$set(echo = TRUE)
library(yardstick)
library(GGally)
library(knitr)
library(caret)
library(glmnet)
library(randomForest)
library(ipred)
```

```{r}
# Import and view head of training data
train_path <- "C:/Users/bbste/Documents/LSE/ST310/ST310-Individual-Project/Data/ST310_challenge1_train.csv"
df_train <- read.csv(train_path)
#head(df_train)
```

```{r}
# Import test data for comparing predictions
test_path <- "C:/Users/bbste/Documents/LSE/ST310/ST310-Individual-Project/Data/ST310_challenge1_test.csv"
df_test <- read.csv(test_path)
#head(df_test)
```


```{r}
# Check for missing values
sum(is.na(df_train))
```
We note that there are no missing values
```{r}
# Check the dimensions of the data
dim(df_train)
```
```{r}
y_value_1 <- length(which(df_train$y==1))
y_value_0 <- length(which(df_train$y==0)) 
```

```{r}
ggplot(data = df_train, aes(x = y)) + 
  geom_bar(fill='red')
```
The outcome data looks relatively balanced although there are more instances of 0 than 1.

```{r}
corr_mat <- round(cor(df_train),2)
 
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
# head(melted_corr_mat)
 
# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2,
                                   fill=value)) +
geom_tile()
```
We cannot infer too much from this but it seems that x3, x4, x5 are highly correlated

```{r}
# Set seed for reproducible results
set.seed(1)

# Split our data into Test and Train in an 80:20 ratio
sample <- sample(c(TRUE, FALSE), nrow(df_train), replace=TRUE, prob=c(0.8,0.2))
train  <- df_train[sample, ]
test   <- df_train[!sample, ]
```

```{r}
logistic_model <- glm(train$y ~ ., family = binomial(), data = train[,-1])
logistic_model |> ggcoef()
```
```{r}
# Create predictions (probabilities) using test data 
logistic_predicted <- predict(logistic_model, test[,-1], type="response")
logistic_predicted <- ifelse(logistic_predicted > 0.55, 1, 0)
```

```{r}
table(test$y, logistic_predicted)
```
```{r}
logistic_error_rate <- mean(logistic_predicted != test$y)
logistic_error_rate
```
Model 2: Random Forest
```{r}
# Train our Random Forest with 
train$y <- as.factor(train$y)

rf_model <- randomForest(train$y ~ ., data = train[,-1], ntree=200)
```


```{r}
# Predictions
rf_predictions <- predict(rf_model, test, type="response")
table(rf_predictions, test$y)
```

```{r}
rf_error_rate <- mean(rf_predictions != test$y)
rf_error_rate
```

```{r}
# Plot the error rate with the number of trees
plot(rf_model)
```
This is an improvement from the logistic regression. However, I think we can do better with Bagging or Boosting so will not tune the Random Forest just yet.

Model 3: Bagging
The benefit of this algorithm is that it will help prevent overfitting since we have many predictors.
```{r}
# Fit the model
bagging_model <- bagging(train$y~., data = train[,-1], coob = T, nbagg = 200 )
```

```{r}
bag_predictions <- predict(bagging_model, test[,-1])
```

```{r}
table(test$y, bag_predictions)
bagging_error_rate <- mean(bag_predictions != test$y)
bagging_error_rate
```

```{r}
# Fit a lasso logistic regression model
xmat <- model.matrix(y ~ ., data = train)[,-1]
lasso_model <- glmnet(xmat, train$y, family="binomial", lambda=0.01, alpha = 1)
```

```{r}
test_as_matrix <- as.matrix(test)
# Predict the class of the test data
lasso_predictions <- predict(lasso_model, newx = test_as_matrix[,-1], type = "response")
```

```{r}
lasso_predictions <- ifelse(lasso_predictions > 0.5, 1,0)
lasso_error_rate <- mean(lasso_predictions != test$y)
lasso_error_rate
```

```{r}
# Fit a lasso logistic regression model
xmat <- model.matrix(y ~ ., data = train)[,-1]
ridge_model <- glmnet(xmat, train$y, family="binomial", lambda=0.01, alpha = 0)
```

```{r}
test_as_matrix <- as.matrix(test)
# Predict the class of the test data
ridge_predictions <- predict(ridge_model, newx = test_as_matrix[,-1], type = "response")
```

```{r}
ridge_predictions <- ifelse(ridge_predictions > 0.55, 1,0)
ridge_error_rate <- mean(ridge_predictions != test$y)
ridge_error_rate
```

```{r}
error_rates <- cbind(logistic_error_rate, ridge_error_rate, lasso_error_rate, rf_error_rate, bagging_error_rate)
colnames(error_rates) <- c("Logistic", "Ridge", "Lasso", "Random Forest", "Bagging")
error_rates |>
  kable()
```
We see that Random Forests and Bagging perform the best, so we will now do some Cross-Validation to decide which one to use as the final model.

```{r}
error_list_seeds <- function(){
  rf_list <- c()
  bag_list <- c()
  
  for(i in 1:3){
    set.seed(i)
  
    # Split our data into Test and Train in an 80:20 ratio
    sample <- sample(c(TRUE, FALSE), nrow(df_train), replace=TRUE, prob=c(0.8,0.2))
    train  <- df_train[sample, ]
    test   <- df_train[!sample, ]
    
    train_as_matrix <- as.matrix(train)
    test_as_matrix <- as.matrix(test)
    
    train$y <- as.factor(train$y)

    rf_model <- randomForest(train$y ~ ., data = train[,-1], ntree=200)

    # Predictions
    rf_predictions <- predict(rf_model, test, type="response")

    rf_error_rate <- mean(rf_predictions != test$y)
    rf_error_rate
    
    # Fit the model
    bagging_model <- bagging(train$y~., data = train[,-1], coob = T, nbagg = 200)

    bag_predictions <- predict(bagging_model, test[,-1])
    bagging_error_rate <- mean(bag_predictions != test$y)
    bagging_error_rate
  
    
    rf_list <- append(rf_list, rf_error_rate)
    bag_list <- append(bag_list, bagging_error_rate)
    
  }
  

  lists <- list("rf" = rf_list, "bag" = bag_list)
  return(lists)
}

```

```{r}
rf_list <- error_list_seeds()$rf
bag_list <- error_list_seeds()$bag
```

```{r}
error_df <- data.frame (seq(1,3), rf_list, bag_list)
#head(error_df)
```

```{r}
colMeans(error_df)[2:3]
```

We will now use our final model to create predictions and export to a csv file.

```{r}
# Import the test data 
final_test_path <- "C:/Users/bbste/Documents/LSE/ST310/ST310-Individual-Project/Data/ST310_challenge1_test.csv"
df_final_test <- read.csv(final_test_path)
#head(df_final_test)
```


```{r}
# We will choose the Random Forest model with 200 trees as our final model
final_model <- rf_model

#Create final predictions
final_predictions <- predict(rf_model, df_final_test, type="response")
# head(final_predictions)
```

```{r}
# DataFrame of predictions

predictions_df <- data.frame("Prediction" = final_predictions)
#head(predictions_df)
```


```{r}
# Export predictions to .csv file
write.csv(predictions_df, "../Predictions/challenge1_44199.csv", row.names=FALSE)
```




